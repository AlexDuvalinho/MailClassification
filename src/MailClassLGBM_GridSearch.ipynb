{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsY_FIQFWisV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/opt/anaconda3/envs/emailClass/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gGqWAs3yoej"
   },
   "outputs": [],
   "source": [
    "# Define parameters (identify by gridsearch)\n",
    "space =  {\n",
    "    'boosting': 'gbdt', \n",
    "    'colsample_bytree': 1, \n",
    "    'learning_rate': hp.choice('learning_rate', [0.1, 0.03, 0.001]), \n",
    "    'max_depth': hp.choice('max_depth', range(5, 20)), \n",
    "    'min_child_samples': hp.choice('min_child_samples', range(20, 101, 10)), \n",
    "    'n_estimators': hp.choice('n_estimators', range(200, 701, 100)),\n",
    "    'num_leaves': hp.choice('num_leaves', range(100, 1001, 100)),  \n",
    "    'reg_alpha': hp.choice('reg_alpha', np.arange(0.0, 1.0, 0.1)), \n",
    "    'reg_lambda': hp.choice('reg_lambda', np.arange(0.0, 1.0, 0.1)), \n",
    "    'subsample': hp.choice('subsample', np.arange(0.1, 1.0, 0.1)),\n",
    "    'objective': 'multiclass',\n",
    "    'num_class':4,\n",
    "    'verbose':1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUO1hIxov9wv"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cCxcgqk3XJYT"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/generated/train_eng.csv')\n",
    "test = pd.read_csv('../data/generated/test_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2vQRWmnteovN",
    "outputId": "69e5befd-f95e-4536-9cc6-978d7fc35252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#ensure there's no null values\n",
    "print(train.isnull().sum().sum())\n",
    "print(test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMGmJqyvz2Gx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24840, 148)\n",
      "(24840,)\n"
     ]
    }
   ],
   "source": [
    "#extract labels & convert to categorical to have our \"y\"\n",
    "labels_train = train['label']\n",
    "\n",
    "#remove labels from train\n",
    "train.drop(columns=['label'], inplace=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3owUy_tr6LGA"
   },
   "source": [
    "Build a normalize that will apply standard scaler and PCA if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXqw1knt-kDR"
   },
   "outputs": [],
   "source": [
    "def NormalizeData(train, CVorTest, PCA_comp = 0.9, ScaleCat = False):\n",
    "    '''\n",
    "    Normalize data using a standard scaler\n",
    "    train:\n",
    "        dataframe that will be use to fit and transformed by the scaler and PCA\n",
    "    CVorTest:\n",
    "        dataframe that will be transformed the scaler and PCA\n",
    "    PCA_comp:\n",
    "        Number of PCA components to keep, if None, PCA not applied\n",
    "    ScaleCat:\n",
    "        Scale or not the categorical columns with the standard scaler\n",
    "    '''\n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    if ScaleCat:\n",
    "        scale_columns = train.columns\n",
    "    else:\n",
    "        scale_columns = [col for col in train.columns[~train.columns.str.startswith('Cat_')]]\n",
    "          \n",
    "    #perform feature scaling    \n",
    "    train.loc[:, scale_columns] = sc.fit_transform(train.loc[:, scale_columns]) \n",
    "    CVorTest.loc[:, scale_columns] = sc.transform(CVorTest.loc[:, scale_columns]) \n",
    "    \n",
    "    if PCA_comp is None:\n",
    "        return train.values, CVorTest.values\n",
    "    \n",
    "    pca = PCA(PCA_comp)\n",
    "    train = pca.fit_transform(train)\n",
    "    CVorTest = pca.transform(CVorTest)\n",
    "    \n",
    "    return train, CVorTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDDXDs2czyDT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24840, 148)\n"
     ]
    }
   ],
   "source": [
    "train, test = NormalizeData(train, test, None)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4O4oe-bnzqOQ"
   },
   "outputs": [],
   "source": [
    "#build the dataset in Lgbm format\n",
    "d_train = lgb.Dataset(train, labels_train)\n",
    "d_test = lgb.Dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtvD7Oj20nfm"
   },
   "outputs": [],
   "source": [
    "#Kaggle is evaluate on the F1 score, let's define this metric for training\n",
    "def f1_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = preds.reshape(len(np.unique(labels)), -1)\n",
    "    preds = preds.T.argmax(axis = 1)\n",
    "    f_score = f1_score(preds, labels, average=\"macro\")\n",
    "    return 'f1_score', f_score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap the model KFold valudation into a function returning the f1 score to optimize then this function\n",
    "#with HyperOpt\n",
    "\n",
    "def evaluateModel(lgb_params):\n",
    "    cv_mod = lgb.cv(lgb_params, d_train, nfold=10, early_stopping_rounds = 25, feval=f1_eval)\n",
    "    #print(lgb_params)\n",
    "    #print(cv_mod['f1_score-mean'][-1], cv_mod['f1_score-stdv'][-1])\n",
    "    lgb_params['f1_score-mean'] = cv_mod['f1_score-mean'][-1]\n",
    "    lgb_params['f1_score-stdv'] = cv_mod['f1_score-stdv'][-1]\n",
    "    \n",
    "    with open ('./LGB_grid_search.csv', 'a+') as fp:\n",
    "        fp.write(str(lgb_params) +'\\n')\n",
    "\n",
    "    return {\n",
    "        'loss': - cv_mod['f1_score-mean'][-1],\n",
    "        'status': STATUS_OK,\n",
    "        'stats_running': STATUS_RUNNING\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "waodv_yXytty",
    "outputId": "6aeaaed2-2da5-49dd-f6e5-27dcf03cc296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [6:26:50<00:00, 116.05s/it, best loss: -0.9648291118427668]  \n"
     ]
    }
   ],
   "source": [
    "#Hyperopt loop for optimization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# Set algoritm parameters\n",
    "algo = partial(tpe.suggest, \n",
    "               n_startup_jobs=-1)\n",
    "\n",
    "# Seting the number of Evals\n",
    "MAX_EVALS= 200\n",
    "\n",
    "# Fit Tree Parzen Estimator\n",
    "best_vals = fmin(evaluateModel, space=space, verbose=1,\n",
    "                 algo=algo, max_evals=MAX_EVALS, trials=trials)\n",
    "\n",
    "# Print best parameters\n",
    "best_params = space_eval(space, best_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDfw25KNWVt9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting': 'gbdt',\n",
       " 'colsample_bytree': 1,\n",
       " 'learning_rate': 0.03,\n",
       " 'max_depth': 15,\n",
       " 'min_child_samples': 30,\n",
       " 'n_estimators': 600,\n",
       " 'num_class': 4,\n",
       " 'num_leaves': 200,\n",
       " 'objective': 'multiclass',\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.2,\n",
       " 'subsample': 0.5,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MailClassLGBM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
