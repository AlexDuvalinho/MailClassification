{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsY_FIQFWisV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/opt/anaconda3/envs/emailClass/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gGqWAs3yoej"
   },
   "outputs": [],
   "source": [
    "#parameters dict for LightGBM\n",
    "lgb_params =  {\n",
    "    'boosting': 'gbdt', \n",
    "    'colsample_bytree': 1, \n",
    "    'learning_rate': 0.1, \n",
    "    'max_depth': 15, \n",
    "    'min_child_samples': 20, \n",
    "    'n_estimators': 500, \n",
    "    'num_leaves': 500,  \n",
    "    'objective': 'multiclass',\n",
    "    'num_class':4,\n",
    "    'reg_alpha': 0.6, \n",
    "    'reg_lambda': 0.3, \n",
    "    'subsample': 0.7,\n",
    "    'verbose':1\n",
    "    }\n",
    "\n",
    "#provided by grid search but LB score is less\n",
    "lgb_params_old =  {\n",
    "'boosting': 'gbdt',\n",
    " 'colsample_bytree': 1,\n",
    " 'learning_rate': 0.03,\n",
    " 'max_depth': 15,\n",
    " 'min_child_samples': 30,\n",
    " 'n_estimators': 600,\n",
    " 'num_class': 4,\n",
    " 'num_leaves': 200,\n",
    " 'objective': 'multiclass',\n",
    " 'reg_alpha': 0.0,\n",
    " 'reg_lambda': 0.2,\n",
    " 'subsample': 0.5,\n",
    " 'verbose': 1}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUO1hIxov9wv"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cCxcgqk3XJYT"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/generated/train_eng.csv')\n",
    "test = pd.read_csv('../data/generated/test_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2vQRWmnteovN",
    "outputId": "69e5befd-f95e-4536-9cc6-978d7fc35252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#ensure that there are not null values\n",
    "print(train.isnull().sum().sum())\n",
    "print(test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMGmJqyvz2Gx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24840, 148)\n",
      "(24840,)\n"
     ]
    }
   ],
   "source": [
    "#extract labels & convert to categorical to have our \"y\"\n",
    "labels_train = train['label']\n",
    "\n",
    "#remove labels from train\n",
    "train.drop(columns=['label'], inplace=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3owUy_tr6LGA"
   },
   "source": [
    "Build a normalize that will apply standard scaler and PCA if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXqw1knt-kDR"
   },
   "outputs": [],
   "source": [
    "def NormalizeData(train, CVorTest, PCA_comp = 0.95, ScaleCat = False):\n",
    "    '''\n",
    "    Normalize data using a standard scaler\n",
    "    train:\n",
    "        dataframe that will be use to fit and transformed by the scaler and PCA\n",
    "    CVorTest:\n",
    "        dataframe that will be transformed the scaler and PCA\n",
    "    PCA_comp:\n",
    "        Number of PCA components to keep, if None, PCA not applied\n",
    "    ScaleCat:\n",
    "        Scale or not the categorical columns with the standard scaler\n",
    "    '''\n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    if ScaleCat:\n",
    "        scale_columns = train.columns\n",
    "    else:\n",
    "        scale_columns = [col for col in train.columns[~train.columns.str.startswith('Cat_')]]\n",
    "          \n",
    "    #perform feature scaling    \n",
    "    train.loc[:, scale_columns] = sc.fit_transform(train.loc[:, scale_columns]) \n",
    "    CVorTest.loc[:, scale_columns] = sc.transform(CVorTest.loc[:, scale_columns]) \n",
    "    \n",
    "    if PCA_comp is None:\n",
    "        return train.values, CVorTest.values\n",
    "    \n",
    "    pca = PCA(PCA_comp)\n",
    "    train = pca.fit_transform(train)\n",
    "    CVorTest = pca.transform(CVorTest)\n",
    "    \n",
    "    return train, CVorTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDDXDs2czyDT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24840, 148)\n"
     ]
    }
   ],
   "source": [
    "train, test = NormalizeData(train, test, None)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4O4oe-bnzqOQ"
   },
   "outputs": [],
   "source": [
    "#build the dataset in Lgbm format\n",
    "d_train = lgb.Dataset(train, labels_train)\n",
    "d_test = lgb.Dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtvD7Oj20nfm"
   },
   "outputs": [],
   "source": [
    "#Kaggle is evaluate on the F1 score, let's define this metric for training\n",
    "def f1_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = preds.reshape(len(np.unique(labels)), -1)\n",
    "    preds = preds.T.argmax(axis = 1)\n",
    "    f_score = f1_score(preds, labels, average=\"macro\")\n",
    "    return 'f1_score', f_score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "waodv_yXytty",
    "outputId": "6aeaaed2-2da5-49dd-f6e5-27dcf03cc296"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/opt/anaconda3/envs/emailClass/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/seb/opt/anaconda3/envs/emailClass/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#perform KFold validation (10 folds)\n",
    "cv_mod = lgb.cv(lgb_params, d_train, nfold=10, early_stopping_rounds = 25, feval=f1_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9643972468274253"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the KFold CV score\n",
    "cv_mod['f1_score-mean'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/opt/anaconda3/envs/emailClass/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.0122088\ttraining's f1_score: 0.999967\n",
      "[200]\ttraining's multi_logloss: 0.00439959\ttraining's f1_score: 1\n",
      "[300]\ttraining's multi_logloss: 0.00342553\ttraining's f1_score: 1\n",
      "[400]\ttraining's multi_logloss: 0.00342497\ttraining's f1_score: 1\n",
      "[500]\ttraining's multi_logloss: 0.00342497\ttraining's f1_score: 1\n"
     ]
    }
   ],
   "source": [
    "#do the training on the full train_set\n",
    "mod = lgb.train(lgb_params, d_train, valid_sets=[d_train], feval=f1_eval, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the F1 score on training\n",
    "f1_score(labels_train, mod.predict(train).argmax(axis = 1), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nD7sdJCW2pt5"
   },
   "source": [
    "## Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sJytJVS1nD3F",
    "outputId": "cf0fe925-f1d3-4be5-8831-5cf6999f9bca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10647, 148)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions\n",
    "preds = mod.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54G4mP3hWp_N"
   },
   "outputs": [],
   "source": [
    "#create submission file\n",
    "pred_df = pd.DataFrame(preds.round().argmax(axis=1), columns=['label'])\n",
    "pred_df.to_csv('../data/generated/submissionLGB.csv', index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features importance\n",
    "    Rerun the cell if no graph display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x3000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "df_train = pd.read_csv('../data/generated/train_eng.csv')\n",
    "\n",
    "feature_imp = pd.DataFrame(sorted(zip(mod.feature_importance(importance_type='split'),df_train.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(20, 30))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MailClassLGBM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
